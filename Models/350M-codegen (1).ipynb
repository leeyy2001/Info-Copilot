{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27230dd6-d0eb-42d9-8f9d-312fa111b144",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.65.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "def subtraction(int a, int b) {\n",
      "    return a - b;\n",
      "}\n",
      "\n",
      "Below this is the function prototype for the unit test.\n",
      "TEST_METHOD(testing1) is just an example do not repeat the contents in the code. Generate unit tests that have the same structure to TEST_METHOD(testing1) within TEST_METHOD(testing2) {\n",
      "\n",
      "#include \"pch.h\"\n",
      "#include \"CppUnitTest.h\"\n",
      "#include \"../CodeGenTest/CodeGenTest.h\"\n",
      "\n",
      "using namespace Microsoft::VisualStudio::CppUnitTestFramework;\n",
      "\n",
      "namespace UnitTestDummy\n",
      "{\n",
      "    TEST_CLASS(UnitTestDummy)\n",
      "    {\n",
      "        TEST_METHOD(testing1) {\n",
      "            Assert::AreEqual(0, CodeGenTest::Sub(2, 2));\n",
      "            Assert::AreEqual(-2, CodeGenTest::Sub(0, 2));\n",
      "        }\n",
      "        \n",
      "        TEST_METHOD(testing2) {\n",
      "            Assert::AreEqual(0, CodeGenTest::Sub(2, 2));\n",
      "            Assert::AreEqual(-2, CodeGenTest::Sub(0, 2));\n",
      "        }\n",
      "    };\n",
      "}\n",
      "Process has ended\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -i https://pypi.python.org/simple\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"codegen-350M-testSave\")\n",
    "\n",
    "text = ''' \n",
    "def subtraction(int a, int b) {\n",
    "    return a - b;\n",
    "}\n",
    "\n",
    "Below this is the function prototype for the unit test.\n",
    "TEST_METHOD(testing1) is just an example do not repeat the contents in the code. Generate unit tests that have the same structure to TEST_METHOD(testing1) within TEST_METHOD(testing2) {\n",
    "\n",
    "#include \"pch.h\"\n",
    "#include \"CppUnitTest.h\"\n",
    "#include \"../CodeGenTest/CodeGenTest.h\"\n",
    "\n",
    "using namespace Microsoft::VisualStudio::CppUnitTestFramework;\n",
    "\n",
    "namespace UnitTestDummy\n",
    "{\n",
    "    TEST_CLASS(UnitTestDummy)\n",
    "    {\n",
    "        TEST_METHOD(testing1) {\n",
    "            Assert::AreEqual(0, CodeGenTest::Sub(2, 2));\n",
    "            Assert::AreEqual(-2, CodeGenTest::Sub(0, 2));\n",
    "        }\n",
    "        \n",
    "        TEST_METHOD(testing2) {\n",
    "'''\n",
    "\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "generated_ids = model.generate(input_ids, max_length=1028)\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "\n",
    "print(\"Process has ended\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
